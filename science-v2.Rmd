---
title: "Science"
author: "Francesco Veri, Gustavo Umbelino"
date: "`r Sys.Date()`"
bibliography: bibliography/refs.bib
link-citations: true
csl: bibliography/apsa.csl
output:
  pdf_document: default
  html_document: default
---

```{r libraries}

library(tidyverse)
library(ggpubr)

```

# Constants
```{r constants}

HUMAN_DATA_FILE <- "human_data.csv"
LLM_DATA_FILE <- "llm_data.csv"
LLMS_FILE <- "private/llms_v3.csv"
OUTPUT_DIR <- "analysis"

SIG_LEVEL <- 0.05
LLM_ITERATIONS <- 5
ITERATIONS <- 1000
NUM_MODELS <- NA

SKIP_HUMAN <- FALSE

time_est <- (LLM_ITERATIONS * 13 * NUM_MODELS * ITERATIONS * 0.002) / 60

cat("LLM time estimate:", time_est / 60, "h")


```

# Functions
```{r functions}
read_output_csv <- function(file_name) {
  read_csv(paste(OUTPUT_DIR, file_name, sep = "/"), show_col_types = FALSE)
}

write_output_csv <- function(data, file_name) {
  write_csv(data, paste(OUTPUT_DIR, file_name, sep = "/"))
}

now_utc <- function() {
   now <- Sys.time()
   attr(now, "tzone") <- "UTC"
   now
}

dri_calc_v3 <- function(data, v1, v2) {
  d <- abs((data[[v1]] - data[[v2]]) / sqrt(2))
  lambda <- 1 - (sqrt(2) / 2)
  
  # Scalar penalty based on strength of signal (|r| and |q|)
  penalty <- ifelse(pmax(abs(data[[v1]]), abs(data[[v2]])) <= 0.2, pmax(abs(data[[v1]]), abs(data[[v2]])) / 0.2, 1)
  
  consistency <- (1 - d) * penalty
  avg_consistency <- mean(consistency)
  
  dri <- 2 * ((avg_consistency - lambda) / (1 - lambda)) - 1
  return(dri)
}

get_dri <- function(data) {
  
  if (nrow(data) < 1) {
    return(NA)
  }
      
  PNums <- data$PNum
  
  Q <- data %>% select(C1:C50)
  R <- data %>% select(P1:P10)
  
  # remove all NA columns (in case there are less than 50
  Q <- Q[, colSums(is.na(Q)) != nrow(Q)]
  R <- R[, colSums(is.na(R)) != nrow(R)]
  
  # transpose data
  Q <- t(Q) %>% as.data.frame()
  R <- t(R) %>% as.data.frame()
  
  # name columns with participant numbers
  colnames(Q) <- PNums
  colnames(R) <- PNums
  
  # obtain a list of correlations without duplicates
  # cor() returns a correlation matrix between Var1 and Var2
  # Var1 and Var2 are the variables being correlated
  # Freq is the correlation
  QWrite <- subset(as.data.frame(as.table(cor(Q, method = "spearman"))),
                   match(Var1, names(Q)) > match(Var2, names(Q)))
  
  RWrite <- subset(as.data.frame(as.table(cor(R, method = "spearman"))),
                   match(Var1, names(R)) > match(Var2, names(R)))
  
  # initialize the output in the first iteration
  IC <- data.frame("P_P" = paste0(QWrite$Var1, '-', QWrite$Var2))
  IC$P1 <- as.numeric(as.character(QWrite$Var1))
  IC$P2 <- as.numeric(as.character(QWrite$Var2))

  # prepare QWrite
  QWrite <- as.data.frame(QWrite$Freq)
  names(QWrite) <- "Q2"
  
  # prepare RWrite for merge
  RWrite <- as.data.frame(RWrite$Freq)
  names(RWrite) <- "R2"
  
  # merge
  IC <- cbind(IC, QWrite, RWrite)
  
  ## IC Points calculations ##
  IC$IC_POST <- 1 - abs((IC$R2 - IC$Q2) / sqrt(2))
  
  ## Group DRI level V3 ##
  DRI_POST_V3 <- dri_calc_v3(IC, 'R2', 'Q2')
  
  return(DRI_POST_V3)
  
}


get_ind_dri <- function(data) {
  
  if (nrow(data) < 1) {
    return(NA)
  }
      
  PNums <- data$PNum
  
  Q <- data %>% select(C1:C50)
  R <- data %>% select(P1:P10)
  
  # remove all NA columns (in case there are less than 50
  Q <- Q[, colSums(is.na(Q)) != nrow(Q)]
  R <- R[, colSums(is.na(R)) != nrow(R)]
  
  # transpose data
  Q <- t(Q) %>% as.data.frame()
  R <- t(R) %>% as.data.frame()
  
  # name columns with participant numbers
  colnames(Q) <- PNums
  colnames(R) <- PNums
  
  # obtain a list of correlations without duplicates
  # cor() returns a correlation matrix between Var1 and Var2
  # Var1 and Var2 are the variables being correlated
  # Freq is the correlation
  QWrite <- subset(as.data.frame(as.table(cor(Q, method = "spearman"))),
                   match(Var1, names(Q)) > match(Var2, names(Q)))
  
  RWrite <- subset(as.data.frame(as.table(cor(R, method = "spearman"))),
                   match(Var1, names(R)) > match(Var2, names(R)))
  
  # initialize the output in the first iteration
  IC <- data.frame("P_P" = paste0(QWrite$Var1, '-', QWrite$Var2))
  IC$P1 <- as.numeric(as.character(QWrite$Var1))
  IC$P2 <- as.numeric(as.character(QWrite$Var2))

  # prepare QWrite
  QWrite <- as.data.frame(QWrite$Freq)
  names(QWrite) <- "Q2"
  
  # prepare RWrite for merge
  RWrite <- as.data.frame(RWrite$Freq)
  names(RWrite) <- "R2"
  
  # merge
  IC <- cbind(IC, QWrite, RWrite)
  
  ## IC Points calculations ##
  IC$IC_POST <- 1 - abs((IC$R2 - IC$Q2) / sqrt(2))
  
  Plist <- unique(c(IC$P1, IC$P2))
  
  Plist <- Plist[order(Plist)]
  
  DRIInd <- data.frame('PNum' = Plist)

  #Add individual-level metrics
  for (i in 1:length(Plist)) {
    
    # calculate updated DRI V3
    DRIInd$DRIPostV3[i] <- dri_calc_v3(
      data = IC  %>% filter(P1 == Plist[i] | P2 == Plist[i]),
      v1 = 'R2',
      v2 = 'Q2'
    )
    
  }
  
  return(DRIInd)
  
}

get_llm_dri <- function(data) {
  
  ind_dri <- get_ind_dri(data)
  llm_ind_dri <- ind_dri %>% filter(PNum == 0)
  
  return(llm_ind_dri[1, 2])
  
}


add_llm_participant <- function(llm_survey_data, data) {
  
  # get llm data
  llm_participant <- llm_survey_data[it, ]
  
  # check if it exists
  if (nrow(llm_participant) == 0) {
    warning(paste("No participant found for", paste(provider, model, survey, sep = "/")))
  }
  
  # create 2 participants, PRE and POST
  llm_participants <- bind_rows(llm_participant, llm_participant)
  llm_participants$PNum <- 0 # PNum = 0 is LLM
  llm_participants$StageID <- c(1,2)
  
  data_with_llm <- bind_rows(data, llm_participants)
  
  return(data_with_llm)
  
}


```


# Data
```{r data}

human_data <- read_output_csv(HUMAN_DATA_FILE)
llm_data <- read_output_csv(LLM_DATA_FILE)

# get models info
models <- read_csv(LLMS_FILE, show_col_types = FALSE) %>%
  filter(included)

```

# Permutation Test Analysis

## Human-Only
```{r analysis}

if (SKIP_HUMAN) {
  res <- read_output_csv("human-only_perm_test_results_v2.csv")
} else {
  
  set.seed(123)
  res <- list()
  perms <- list()
  j <- 0
  
  # select pre and post deliberation
  data <- human_data #%>% filter(StageID == 2)
  
  cases <- sort(unique(data$Case))
  
  for (case in cases) {
    
    # for progress checking
    j <- j + 1
    cat(paste0("[",j,"/",length(cases),"] ", "Starting: ", case, " - "))
    
    # get case data
    data_case <- data %>% filter(Case == case)
    
    # get observed DRI
    obs_pre_dri <- get_dri(data_case %>% filter(StageID == 1))
    obs_post_dri <- get_dri(data_case %>% filter(StageID == 2))
    
    # initiate results
    df_pre <- tibble(
      case = case,
      dri = obs_pre_dri,
      source = "observed",
      stage = 1
    )
    
    df_post <- tibble(
      case = case,
      dri = obs_post_dri,
      source = "observed",
      stage = 2
    )
    
    df <- bind_rows(df_pre, df_post)
    
    # get preferences
    shuffle_cols <- grep("^StageID$", names(data_case), value = TRUE)
    shuffled_data <- data_case
    
    
    dri_shuffle <- list()
    time_start <- Sys.time()
    
    # permutation loop
    for (i in 1:ITERATIONS) {
      shuffled_data[pref_cols] <- shuffled_data[sample(1:nrow(shuffled_data)), pref_cols]
      
      # GET DRI "PRE"
      dri_shuffle[[length(dri_shuffle)+1]] <- tibble(
        case = case,
        dri = get_dri(shuffled_data %>% filter(StageID == 1)),
        source = "permutation",
        stage = 0,
        permutation = length(dri_shuffle)+1,
      )
      
      # GET DRI "POST"
      dri_shuffle[[length(dri_shuffle)+1]] <- tibble(
        case = case,
        dri = get_dri(shuffled_data %>% filter(StageID == 2)),
        source = "permutation",
        stage = 0,
        permutation = length(dri_shuffle)+1,
      )
      
      
    }
    
    time_end <- Sys.time()
    
    elapsed_time <- as.numeric(difftime(time_end, time_start, units = "secs"))
    
    cat(paste0("elapsed time: ", round(elapsed_time, 2), "s\n"))
  
    
    dri_shuffle <- bind_rows(dri_shuffle)
    
    df <- bind_rows(df, dri_shuffle)
    
    perms[[length(perms)+1]] <- df
    
    # FIXME: this doesn't seem right...
    p <- nrow(dri_shuffle %>% filter(dri >= obs_post_dri)) / nrow(dri_shuffle)
    
    res[[length(res) + 1]] <- tibble(
      case = case,
      N = nrow(data_case),
      observed_pre_dri = obs_pre_dri,
      observed_post_dri = obs_post_dri,
      mean_perm_dri = mean(dri_shuffle$dri, na.rm = TRUE),
      p = p,
      elapsed_time_s = elapsed_time,
    )
    
  }
  
  res <- bind_rows(res)
  perms <- bind_rows(perms)
  
  write_output_csv(res, "human-only_perm_test_results_v2.csv")
  write_output_csv(perms, "human-only_perm_data_v2.csv")
  
  perms$stage <- as.factor(perms$stage)
  
  perms %>%
    gghistogram(
      x = "dri",
      facet.by = "case",
      fill = "stage",
      add = "mean",
      rug = TRUE,
      # color = "p.sig",
      title = "Permutation test",
      subtitle = "Pre/Post-Deliberation DRI",
      caption = paste(ITERATIONS, "permutations"),
    ) -> plot
  
  plot
    
  ggsave(
    paste(OUTPUT_DIR, "plots", paste0("all-perm-v2.png"), sep = "/"),
    plot,
    width = 10,
    height = 6
  )
  
}

```

## Select deliberative cases
```{r select cases}

deliberative_cases <- res %>% filter(p <= SIG_LEVEL)

deliberative_cases %>%
  select(-elapsed_time_s) %>%
  knitr::kable(caption = "Deliberative Cases", digits = 3)

```


```{r test}

# group dri == mean individual dri
ind_dri <- get_ind_dri(data_case)

get_dri(data_case)

mean(ind_dri$DRIPostV3)

```


## LLM 
```{r llm}

set.seed(123)
res <- list()
perms <- list()
j <- 0
m <- 0 

# select subset of data to analyse: post-deliberation
data <- human_data %>% filter(StageID == 2)

cases <- sort(unique(deliberative_cases$case))

models <- sort(unique(models$model))

if (NUM_MODELS) {
  models <- models[1:NUM_MODELS]
}

for (case in cases) {
  
  # for progress checking
  j <- j + 1
  cat(paste0("[",j,"/",length(cases),"] ", "Starting: ", case, "\n"))
  
  # get case data
  data_case <- data %>% filter(Case == case)
  
  survey_case <- unique(data_case$survey)
  
  m <- 0
  for (model in models) {
    
    m <- m + 1
    cat(paste0("- [",m,"/",length(models),"] ", "Model: ", model, "\n"))
    
    # add LLM participant
    llm_case_data <- llm_data %>%
      filter(model == !!model, survey == survey_case) %>%
      arrange(created_at)
    
    for (it in 1:LLM_ITERATIONS) {
      
      cat(paste0("- - [",it,"] "))
      
      llm_participant <- llm_case_data[it, ]
      llm_participant$PNum <- 0
      
      data_case_with_llm <- bind_rows(data_case, llm_participant)
      
      # get observed DRI
      obs_dri <- get_llm_dri(data_case_with_llm)
      
      # initiate results
      df <- tibble(
        model = model,
        it = it,
        case = case,
        dri = obs_dri,
        source = "observed"
      )
      
      # get preferences
      pref_cols <- grep("^P\\d", names(data_case_with_llm), value = TRUE)
      shuffled_data <- data_case_with_llm
      
      
      dri_shuffle <- list()
      time_start <- Sys.time()
      
      # permutation loop
      for (i in 1:ITERATIONS) {
        shuffled_data[pref_cols] <- shuffled_data[sample(1:nrow(shuffled_data)), pref_cols]
        
        dri_shuffle[[i]] <- tibble(
          model = model,
          it = it,
          case = case,
          dri = get_dri(shuffled_data),
          source = "perm",
          iteration = i,
        )
        
      }
      
      time_end <- Sys.time()
      
      elapsed_time <- as.numeric(difftime(time_end, time_start, units = "secs"))
      
      cat(paste0("elapsed time: ", round(elapsed_time, 2), "s\n"))
    
      
      dri_shuffle <- bind_rows(dri_shuffle)
      
      df <- bind_rows(df, dri_shuffle)
      
      perms[[length(perms)+1]] <- df
      
      p <- nrow(dri_shuffle %>% filter(dri >= obs_dri)) / nrow(dri_shuffle)
      
      res[[length(res) + 1]] <- tibble(
        model = model,
        it = it,
        case = case,
        N = nrow(data_case),
        observed_dri = obs_dri,
        mean_perm_dri = mean(dri_shuffle$dri, na.rm = TRUE),
        p = p,
        elapsed_time_s = elapsed_time,
      )
      
      
    }
    
  }
  
}

res <- bind_rows(res)
perms <- bind_rows(perms)

write_output_csv(res %>% filter(!is.na(observed_dri)), "LLM_perm_test_results.csv")
write_output_csv(perms, "LLM_perm_data.csv")

# perms %>%
#   gghistogram(
#     x = "dri",
#     facet.by = c("model", "case"),
#     fill = "source",
#     add = "mean",
#     rug = TRUE,
#     title = "Permutation test",
#     subtitle = "Post-deliberation DRI",
#     caption = paste(ITERATIONS, "iterations"),
#   ) -> plot
# 
# plot
#   
# ggsave(
#   paste(OUTPUT_DIR, "plots", paste0("all-llm-perm.png"), sep = "/"),
#   plot,
#   width = 15,
#   height = 6
# )

res %>%
  filter(!is.na(observed_dri)) %>%
  group_by(model) %>%
  summarise(
    N = n(),
    sig.count = sum(p < SIG_LEVEL),
    sig.rate = sig.count / N,
  ) %>%
  arrange(-sig.rate) %>%
  write_output_csv(paste0(LLM_ITERATIONS,"-responses_", ITERATIONS, "-perms",length(models),"-models_summary.csv"))


res %>%
  group_by(case) %>%
  summarise(
    N = n(),
    sig.count = sum(p < SIG_LEVEL),
    sig.rate = sig.count / N,
  ) %>%
  arrange(-sig.rate)

```

References:
* https://bookdown.org/content/50286a34-7e39-4500-8dd2-62bf686c1710/permutation-testing.html#t-test-permutation
* https://www.jwilber.me/permutationtest/ 

